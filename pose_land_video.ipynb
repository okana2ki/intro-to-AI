{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "10_y8QmW6botIbFPPoREvc_HF7_jUFUv_",
      "authorship_tag": "ABX9TyP60VoymW5TnfIfq7sw1ZXZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/okana2ki/intro-to-AI/blob/main/pose_land_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ダンス動画ファイルからランドマーク検出（旧モデル）"
      ],
      "metadata": {
        "id": "z-KJISF42N9q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDFV25k9KCJB"
      },
      "outputs": [],
      "source": [
        "!pip install mediapipe opencv-python"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 音声なし版"
      ],
      "metadata": {
        "id": "ZbBuVeeqPqoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "\n",
        "# MediaPipe Poseの初期化\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose()\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# 動画ファイルの読み込み\n",
        "input_video_path = '/content/drive/MyDrive/Colab_files/dance-sample.mp4'\n",
        "cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "# 動画ファイルのプロパティ取得\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# 出力動画ファイルの設定\n",
        "output_video_path = '/content/drive/MyDrive/Colab_files/dance-sample-l.mp4'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # BGR画像をRGBに変換\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # ポーズランドマークの検出\n",
        "    results = pose.process(rgb_frame)\n",
        "\n",
        "    # ランドマークの描画\n",
        "    if results.pose_landmarks:\n",
        "        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "\n",
        "    # フレームを書き込み\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "pose.close()\n",
        "\n",
        "print(f'Output video saved to {output_video_path}')"
      ],
      "metadata": {
        "id": "Sp1ZJnlFKIb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 音声あり版"
      ],
      "metadata": {
        "id": "igBPs57aPydD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe opencv-python moviepy\n",
        "!sudo apt-get install ffmpeg"
      ],
      "metadata": {
        "id": "UVYOBHPLP2O1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "from moviepy.editor import VideoFileClip, AudioFileClip\n",
        "\n",
        "# MediaPipe Poseの初期化\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose()\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# 入力動画ファイルのパス\n",
        "input_video_path = '/content/drive/MyDrive/Colab_files/dance-sample.mp4'\n",
        "\n",
        "# MoviePyを使って動画と音声を読み込み\n",
        "clip = VideoFileClip(input_video_path)\n",
        "audio = clip.audio\n",
        "\n",
        "# OpenCVを使って動画ファイルを読み込み\n",
        "cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "# 動画ファイルのプロパティ取得\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# 出力動画ファイルの設定\n",
        "output_video_path = 'output_with_landmarks.mp4'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # BGR画像をRGBに変換\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # ポーズランドマークの検出\n",
        "    results = pose.process(rgb_frame)\n",
        "\n",
        "    # ランドマークの描画\n",
        "    if results.pose_landmarks:\n",
        "        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "\n",
        "    # フレームを書き込み\n",
        "    out.write(frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "pose.close()\n",
        "\n",
        "# MoviePyを使って映像と音声を結合\n",
        "final_clip = VideoFileClip(output_video_path)\n",
        "final_clip = final_clip.set_audio(audio)\n",
        "final_clip.write_videofile(\"final_output_with_audio.mp4\", codec='libx264', audio_codec='aac')\n",
        "\n",
        "print('Output video saved as final_output_with_audio.mp4')"
      ],
      "metadata": {
        "id": "2Srf9daATJW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ワールド座標のファイル保存を追加"
      ],
      "metadata": {
        "id": "GfHRiXVPWIn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import csv\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# MediaPipe Poseの初期化\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(model_complexity=1, enable_segmentation=False, min_detection_confidence=0.5)\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# 入力動画ファイルのパス\n",
        "input_video_path = '/content/drive/MyDrive/Colab_files/dance-sample.mp4'\n",
        "\n",
        "# MoviePyを使って動画と音声を読み込み\n",
        "clip = VideoFileClip(input_video_path)\n",
        "audio = clip.audio\n",
        "\n",
        "# OpenCVを使って動画ファイルを読み込み\n",
        "cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "# 動画ファイルのプロパティ取得\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# 出力動画ファイルの設定\n",
        "output_video_path = 'output_with_landmarks.mp4'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# CSVファイルの設定\n",
        "csv_file_path = 'landmarks_world_coordinates.csv'\n",
        "csv_file = open(csv_file_path, mode='w', newline='')\n",
        "csv_writer = csv.writer(csv_file)\n",
        "csv_writer.writerow(['frame', 'landmark_index', 'x', 'y', 'z', 'visibility'])\n",
        "\n",
        "frame_index = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # BGR画像をRGBに変換\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # ポーズランドマークの検出\n",
        "    results = pose.process(rgb_frame)\n",
        "\n",
        "    # ランドマークの描画\n",
        "    if results.pose_landmarks:\n",
        "        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "\n",
        "        # ランドマークのワールド座標を取得\n",
        "        for i, landmark in enumerate(results.pose_world_landmarks.landmark):\n",
        "            csv_writer.writerow([frame_index, i, landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
        "\n",
        "    # フレームを書き込み\n",
        "    out.write(frame)\n",
        "    frame_index += 1\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "pose.close()\n",
        "csv_file.close()\n",
        "\n",
        "# MoviePyを使って映像と音声を結合\n",
        "final_clip = VideoFileClip(output_video_path)\n",
        "final_clip = final_clip.set_audio(audio)\n",
        "final_clip.write_videofile(\"final_output_with_audio.mp4\", codec='libx264', audio_codec='aac')\n",
        "\n",
        "print('Output video saved as final_output_with_audio.mp4')\n",
        "print(f'Landmark world coordinates saved as {csv_file_path}')"
      ],
      "metadata": {
        "id": "m7V2aFVAWPnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## num_poses=2と指定できるよう、変更しようとしてデバッグ中"
      ],
      "metadata": {
        "id": "7CoRRcdUydDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2WUlPD2HkEi",
        "outputId": "a2e9cee8-86f0-4580-9634-e63801cd213e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.10/dist-packages (0.10.14)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.25.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.25.3)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.7)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# MediaPipe Poseの初期化\n",
        "from mediapipe.tasks.python import vision\n",
        "from mediapipe.tasks.python.vision import PoseLandmarker, PoseLandmarkerOptions, RunningMode\n",
        "from mediapipe.framework.formats import landmark_pb2\n",
        "\n",
        "# モデルファイルのパスを指定\n",
        "model_path = '/content/drive/MyDrive/Colab_files/pose_landmarker_full.task'\n",
        "\n",
        "# Set up the options with num_poses\n",
        "options = PoseLandmarkerOptions(\n",
        "    base_options=vision.BaseOptions(model_asset_path=model_path),\n",
        "    running_mode=RunningMode.VIDEO,\n",
        "    num_poses=2  # Set the number of poses to detect\n",
        ")\n",
        "\n",
        "# Initialize drawing utilities\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "# Create the pose landmarker instance\n",
        "with PoseLandmarker.create_from_options(options) as landmarker:\n",
        "    # 入力動画ファイルのパス\n",
        "    input_video_path = '/content/drive/MyDrive/Colab_files/dance-sample.mp4'\n",
        "\n",
        "    # MoviePyを使って動画と音声を読み込み\n",
        "    clip = VideoFileClip(input_video_path)\n",
        "    audio = clip.audio\n",
        "\n",
        "    # OpenCVを使って動画ファイルを読み込み\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "    # 出力動画ファイルの設定\n",
        "    output_video_path = 'output_with_poses.mp4'\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # フレームをBGRからRGBに変換\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
        "\n",
        "        # タイムスタンプを取得し、ミリ秒からマイクロ秒に変換\n",
        "        timestamp_ms = int(cap.get(cv2.CAP_PROP_POS_MSEC) * 1000)\n",
        "\n",
        "        # ポーズ検出を実行\n",
        "        pose_landmarker_result = landmarker.detect_for_video(mp_image, timestamp_ms)\n",
        "\n",
        "        # ポーズの描画\n",
        "        for pose_landmarks in pose_landmarker_result.pose_landmarks:\n",
        "            # Convert pose_landmarks to a NormalizedLandmarkList\n",
        "            landmark_list = landmark_pb2.NormalizedLandmarkList(\n",
        "                landmark=pose_landmarks\n",
        "            )\n",
        "            mp_drawing.draw_landmarks(\n",
        "                frame,\n",
        "                landmark_list,\n",
        "                mp_pose.POSE_CONNECTIONS\n",
        "            )\n",
        "\n",
        "        # フレームを書き込み\n",
        "        out.write(frame)\n",
        "\n",
        "        # フレームを表示（オプション）\n",
        "        cv2.imshow('MediaPipe Pose', frame)\n",
        "        if cv2.waitKey(5) & 0xFF == 27:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    # MoviePyを使って出力動画に音声を追加\n",
        "    final_clip = VideoFileClip(output_video_path).set_audio(audio)\n",
        "    final_clip.write_videofile('final_output_with_audio.mp4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "OYYiT6ZSHnV-",
        "outputId": "3adb6d5f-0bff-464c-acc7-d50d62dd21f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'mediapipe.tasks.python.vision' has no attribute 'BaseOptions'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f4f70cbbcfef>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Set up the options with num_poses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m options = PoseLandmarkerOptions(\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mbase_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_asset_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mrunning_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRunningMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVIDEO\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mnum_poses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m  \u001b[0;31m# Set the number of poses to detect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'mediapipe.tasks.python.vision' has no attribute 'BaseOptions'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# MediaPipe Poseの初期化\n",
        "BaseOptions = mp.tasks.BaseOptions\n",
        "PoseLandmarker = mp.tasks.vision.PoseLandmarker\n",
        "PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions\n",
        "VisionRunningMode = mp.tasks.vision.RunningMode\n",
        "\n",
        "# モデルファイルのパスを指定\n",
        "model_path = '/content/drive/MyDrive/Colab_files/pose_landmarker_full.task'\n",
        "\n",
        "# Set up the options with num_poses\n",
        "options = PoseLandmarkerOptions(\n",
        "    base_options=BaseOptions(model_asset_path=model_path),\n",
        "    running_mode=VisionRunningMode.VIDEO,\n",
        "    num_poses=2  # Set the number of poses to detect\n",
        ")\n",
        "\n",
        "# Initialize drawing utilities\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "# Create the pose landmarker instance\n",
        "with PoseLandmarker.create_from_options(options) as landmarker:\n",
        "    # 入力動画ファイルのパス\n",
        "    input_video_path = '/content/drive/MyDrive/Colab_files/dance-sample.mp4'\n",
        "\n",
        "    # MoviePyを使って動画と音声を読み込み\n",
        "    clip = VideoFileClip(input_video_path)\n",
        "    audio = clip.audio\n",
        "\n",
        "    # OpenCVを使って動画ファイルを読み込み\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "    # 出力動画ファイルの設定\n",
        "    output_video_path = 'output_with_poses.mp4'\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # フレームをBGRからRGBに変換\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
        "\n",
        "        # タイムスタンプを取得し、ミリ秒からマイクロ秒に変換\n",
        "        timestamp_ms = int(cap.get(cv2.CAP_PROP_POS_MSEC) * 1000)\n",
        "\n",
        "        # ポーズ検出を実行\n",
        "        pose_landmarker_result = landmarker.detect_for_video(mp_image, timestamp_ms)\n",
        "\n",
        "        # ポーズの描画\n",
        "        for pose_landmarks in pose_landmarker_result.pose_landmarks:\n",
        "            # Convert pose_landmarks to a NormalizedLandmarkList\n",
        "            landmark_list = mp.tasks.vision.core.landmark_pb2.NormalizedLandmarkList(\n",
        "                landmark=pose_landmarks\n",
        "            )\n",
        "            mp_drawing.draw_landmarks(\n",
        "                frame,\n",
        "                landmark_list,\n",
        "                mp_pose.POSE_CONNECTIONS\n",
        "            )\n",
        "\n",
        "        # フレームを書き込み\n",
        "        out.write(frame)\n",
        "\n",
        "        # フレームを表示（オプション）\n",
        "        cv2.imshow('MediaPipe Pose', frame)\n",
        "        if cv2.waitKey(5) & 0xFF == 27:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    # MoviePyを使って出力動画に音声を追加\n",
        "    final_clip = VideoFileClip(output_video_path).set_audio(audio)\n",
        "    final_clip.write_videofile('final_output_with_audio.mp4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "hwPTU-yQG-Na",
        "outputId": "21b59c22-b94c-410a-d99c-d8a7ad06fa9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'mediapipe.tasks.python.vision' has no attribute 'core'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6e2abcee3eed>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpose_landmarks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpose_landmarker_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m# Convert pose_landmarks to a NormalizedLandmarkList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             landmark_list = mp.tasks.vision.core.landmark_pb2.NormalizedLandmarkList(\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0mlandmark\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             )\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'mediapipe.tasks.python.vision' has no attribute 'core'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# MediaPipe Poseの初期化\n",
        "BaseOptions = mp.tasks.BaseOptions\n",
        "PoseLandmarker = mp.tasks.vision.PoseLandmarker\n",
        "PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions\n",
        "VisionRunningMode = mp.tasks.vision.RunningMode\n",
        "\n",
        "# モデルファイルのパスを指定\n",
        "model_path = '/content/drive/MyDrive/Colab_files/pose_landmarker_full.task'\n",
        "\n",
        "# Set up the options with num_poses\n",
        "options = PoseLandmarkerOptions(\n",
        "    base_options=BaseOptions(model_asset_path=model_path),\n",
        "    running_mode=VisionRunningMode.VIDEO,\n",
        "    num_poses=2  # Set the number of poses to detect\n",
        ")\n",
        "\n",
        "# Initialize drawing utilities\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Create the pose landmarker instance\n",
        "with PoseLandmarker.create_from_options(options) as landmarker:\n",
        "    # 入力動画ファイルのパス\n",
        "    input_video_path = '/content/drive/MyDrive/Colab_files/dance-sample.mp4'\n",
        "\n",
        "    # MoviePyを使って動画と音声を読み込み\n",
        "    clip = VideoFileClip(input_video_path)\n",
        "    audio = clip.audio\n",
        "\n",
        "    # OpenCVを使って動画ファイルを読み込み\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "    # 出力動画ファイルの設定\n",
        "    output_video_path = 'output_with_poses.mp4'\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # フレームをBGRからRGBに変換\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
        "\n",
        "        # タイムスタンプを取得し、ミリ秒からマイクロ秒に変換\n",
        "        timestamp_ms = int(cap.get(cv2.CAP_PROP_POS_MSEC) * 1000)\n",
        "\n",
        "        # ポーズ検出を実行\n",
        "        pose_landmarker_result = landmarker.detect_for_video(mp_image, timestamp_ms)\n",
        "\n",
        "        # ポーズの描画\n",
        "        for pose_landmarks in pose_landmarker_result.pose_landmarks:\n",
        "            # Convert pose_landmarks to a NormalizedLandmarkList\n",
        "            landmark_list = mp.framework.formats.landmark_pb2.NormalizedLandmarkList(\n",
        "                landmark=pose_landmarks\n",
        "            )\n",
        "            mp_drawing.draw_landmarks(\n",
        "                frame,\n",
        "                landmark_list,\n",
        "                mp.solutions.pose.POSE_CONNECTIONS,\n",
        "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
        "            )\n",
        "\n",
        "        # フレームを書き込み\n",
        "        out.write(frame)\n",
        "\n",
        "        # フレームを表示（オプション）\n",
        "        cv2.imshow('MediaPipe Pose', frame)\n",
        "        if cv2.waitKey(5) & 0xFF == 27:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    # MoviePyを使って出力動画に音声を追加\n",
        "    final_clip = VideoFileClip(output_video_path).set_audio(audio)\n",
        "    final_clip.write_videofile('final_output_with_audio.mp4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "MQCcRRSJGe3s",
        "outputId": "eac88af5-4902-453e-a02d-fefc830cd480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'mediapipe' has no attribute 'framework'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-d51f9a64f2ba>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpose_landmarks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpose_landmarker_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;31m# Convert pose_landmarks to a NormalizedLandmarkList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             landmark_list = mp.framework.formats.landmark_pb2.NormalizedLandmarkList(\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0mlandmark\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             )\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'mediapipe' has no attribute 'framework'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# MediaPipe Poseの初期化\n",
        "BaseOptions = mp.tasks.BaseOptions\n",
        "PoseLandmarker = mp.tasks.vision.PoseLandmarker\n",
        "PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions\n",
        "VisionRunningMode = mp.tasks.vision.RunningMode\n",
        "\n",
        "# モデルファイルのパスを指定\n",
        "model_path = '/content/drive/MyDrive/Colab_files/pose_landmarker_full.task'\n",
        "\n",
        "# Set up the options with num_poses\n",
        "options = PoseLandmarkerOptions(\n",
        "    base_options=BaseOptions(model_asset_path=model_path),\n",
        "    running_mode=VisionRunningMode.VIDEO,\n",
        "    num_poses=2  # Set the number of poses to detect\n",
        ")\n",
        "\n",
        "# Initialize drawing utilities\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Create the pose landmarker instance\n",
        "with PoseLandmarker.create_from_options(options) as landmarker:\n",
        "\n",
        "    # 入力動画ファイルのパス\n",
        "    input_video_path = '/content/drive/MyDrive/Colab_files/dance-sample.mp4'\n",
        "\n",
        "    # MoviePyを使って動画と音声を読み込み\n",
        "    clip = VideoFileClip(input_video_path)\n",
        "    audio = clip.audio\n",
        "\n",
        "    # OpenCVを使って動画ファイルを読み込み\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "    # 出力動画ファイルの設定\n",
        "    output_video_path = 'output_with_poses.mp4'\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, 30.0, (int(cap.get(3)), int(cap.get(4))))\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # フレームをBGRからRGBに変換\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
        "\n",
        "        # タイムスタンプを取得し、ミリ秒からマイクロ秒に変換\n",
        "        timestamp_ms = int(cap.get(cv2.CAP_PROP_POS_MSEC) * 1000)\n",
        "\n",
        "        # ポーズ検出を実行\n",
        "        pose_landmarker_result = landmarker.detect_for_video(mp_image, timestamp_ms)\n",
        "\n",
        "        # ポーズの描画\n",
        "        for pose_landmarks in pose_landmarker_result.pose_landmarks:\n",
        "            # Convert pose_landmarks to a NormalizedLandmarkList\n",
        "            pose_landmark_list = mp.tasks.components.containers.NormalizedLandmarkList(\n",
        "                landmarks=pose_landmarks\n",
        "            )\n",
        "            mp_drawing.draw_landmarks(\n",
        "                frame,\n",
        "                pose_landmark_list,\n",
        "                mp.solutions.pose.POSE_CONNECTIONS,\n",
        "                landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n",
        "            )\n",
        "\n",
        "        # フレームを書き込み\n",
        "        out.write(frame)\n",
        "\n",
        "        # フレームを表示（オプション）\n",
        "        cv2.imshow('MediaPipe Pose', frame)\n",
        "        if cv2.waitKey(5) & 0xFF == 27:\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    # MoviePyを使って出力動画に音声を追加\n",
        "    final_clip = VideoFileClip(output_video_path).set_audio(audio)\n",
        "    final_clip.write_videofile('final_output_with_audio.mp4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "enVfo-vSF7DV",
        "outputId": "d3797e69-ad19-4902-ddfb-b4b4feef655e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'mediapipe.tasks.python.components.containers' has no attribute 'NormalizedLandmarkList'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-73bb13930427>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpose_landmarks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpose_landmarker_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# Convert pose_landmarks to a NormalizedLandmarkList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             pose_landmark_list = mp.tasks.components.containers.NormalizedLandmarkList(\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0mlandmarks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             )\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'mediapipe.tasks.python.components.containers' has no attribute 'NormalizedLandmarkList'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ランドマークを上から見た映像に変換（音声付き）\n",
        "* 下から見た映像になってるっぽいので、後で上から見た映像になるように修正。\n",
        "* 右足を上げたタイミングで、本来は右足首の垂直方向の位置が変わるだけで水平方向の位置は変わらないはずだが、水平方向の位置が変わってるっぽいところも要改善。奥行方向に位置推定は難しいということか？\n",
        "\n"
      ],
      "metadata": {
        "id": "d6vuVZ8WZnOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe opencv-python moviepy\n",
        "!sudo apt-get install ffmpeg"
      ],
      "metadata": {
        "id": "taqJfWSBZ0Je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "from moviepy.editor import VideoFileClip\n",
        "import numpy as np\n",
        "\n",
        "# MediaPipe Poseの初期化\n",
        "mp_pose = mp.solutions.pose\n",
        "pose = mp_pose.Pose(model_complexity=1, enable_segmentation=False, min_detection_confidence=0.5)\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# 入力動画ファイルのパス\n",
        "input_video_path = '/content/drive/MyDrive/Colab_files/dance-sample.mp4'\n",
        "\n",
        "# MoviePyを使って動画と音声を読み込み\n",
        "clip = VideoFileClip(input_video_path)\n",
        "audio = clip.audio\n",
        "\n",
        "# OpenCVを使って動画ファイルを読み込み\n",
        "cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "# 動画ファイルのプロパティ取得\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "# 上から見た映像の設定\n",
        "top_view_width = 800\n",
        "top_view_height = 800\n",
        "\n",
        "# 出力動画ファイルの設定\n",
        "output_video_path = 'output_with_top_view.mp4'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (top_view_width, top_view_height))\n",
        "\n",
        "# 足首、かかと、爪先のランドマークインデックス\n",
        "highlight_landmarks = [mp_pose.PoseLandmark.LEFT_ANKLE, mp_pose.PoseLandmark.RIGHT_ANKLE,\n",
        "                       mp_pose.PoseLandmark.LEFT_HEEL, mp_pose.PoseLandmark.RIGHT_HEEL,\n",
        "                       mp_pose.PoseLandmark.LEFT_FOOT_INDEX, mp_pose.PoseLandmark.RIGHT_FOOT_INDEX]\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # BGR画像をRGBに変換\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # ポーズランドマークの検出\n",
        "    results = pose.process(rgb_frame)\n",
        "\n",
        "    # 空のトップビュー画像を作成\n",
        "    top_view_frame = np.zeros((top_view_height, top_view_width, 3), dtype=np.uint8)\n",
        "\n",
        "    # ランドマークの描画\n",
        "    if results.pose_landmarks:\n",
        "        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
        "\n",
        "        # ランドマークのワールド座標を取得\n",
        "        landmarks = results.pose_world_landmarks.landmark\n",
        "        for i, landmark in enumerate(landmarks):\n",
        "            # ワールド座標をトップビューの座標に変換\n",
        "            x = int((landmark.x + 0.5) * top_view_width)\n",
        "            y = int((landmark.z + 0.5) * top_view_height)\n",
        "\n",
        "            # 特定のランドマークを強調表示\n",
        "            if i in highlight_landmarks:\n",
        "                color = (0, 0, 255)  # 赤色\n",
        "            else:\n",
        "                color = (0, 255, 0)  # 緑色\n",
        "\n",
        "            # トップビューにランドマークを描画\n",
        "            cv2.circle(top_view_frame, (x, y), 5, color, -1)\n",
        "\n",
        "        # ランドマーク同士を線で結ぶ\n",
        "        for connection in mp_pose.POSE_CONNECTIONS:\n",
        "            start_idx = connection[0]\n",
        "            end_idx = connection[1]\n",
        "            start = landmarks[start_idx]\n",
        "            end = landmarks[end_idx]\n",
        "            start_point = (int((start.x + 0.5) * top_view_width), int((start.z + 0.5) * top_view_height))\n",
        "            end_point = (int((end.x + 0.5) * top_view_width), int((end.z + 0.5) * top_view_height))\n",
        "            cv2.line(top_view_frame, start_point, end_point, (255, 255, 255), 2)\n",
        "\n",
        "    # フレームを書き込み\n",
        "    out.write(top_view_frame)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "pose.close()\n",
        "\n",
        "# MoviePyを使って映像と音声を結合\n",
        "final_clip = VideoFileClip(output_video_path)\n",
        "final_clip = final_clip.set_audio(audio)\n",
        "final_clip.write_videofile(\"final_output_with_audio.mp4\", codec='libx264', audio_codec='aac')\n",
        "\n",
        "print('Output video saved as final_output_with_audio.mp4')"
      ],
      "metadata": {
        "id": "x0w00o_ciLor"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}