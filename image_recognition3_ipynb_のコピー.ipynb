{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/okana2ki/intro-to-AI/blob/main/image_recognition3_ipynb_%E3%81%AE%E3%82%B3%E3%83%94%E3%83%BC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_c4lddgZvU_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "848af0bc-6eb1-4dda-8db2-293653379941"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 90.3MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "画像のURLを入力してください（終了するには'q'を入力）：https://www5.city.kyoto.jp/zoo/assets/images/mv/04.jpg\n",
            "クラス: red panda , 確信度: 99.97879028320312\n",
            "クラス: giant panda , 確信度: 0.010443676263093948\n",
            "クラス: European polecat , 確信度: 0.006785721052438021\n",
            "\n",
            "==================================================\n",
            "\n",
            "画像のURLを入力してください（終了するには'q'を入力）：q\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import urllib.request\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "\n",
        "# ImageNetのクラス名をダウンロードします\n",
        "class_idx = json.load(urllib.request.urlopen('https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json'))\n",
        "\n",
        "# 学習済みのResNet50モデルをロードします\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "resnet.eval()\n",
        "\n",
        "# 入力画像を処理するための変換を定義します\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "while True:\n",
        "    # ユーザーに画像URLを入力させます\n",
        "    img_url = input(\"画像のURLを入力してください（終了するには'q'を入力）：\")\n",
        "\n",
        "    if img_url.lower() == 'q':\n",
        "        break\n",
        "\n",
        "    # URLから画像をダウンロードし、メモリ内で開きます\n",
        "    with urllib.request.urlopen(img_url) as url:\n",
        "        img = Image.open(url)\n",
        "\n",
        "    # 画像を変換します\n",
        "    img_t = transform(img)\n",
        "    batch_t = torch.unsqueeze(img_t, 0)\n",
        "\n",
        "    # モデルを使って画像を推測します\n",
        "    resnet.eval()\n",
        "    out = resnet(batch_t)\n",
        "\n",
        "    # ソフトマックス関数を適用して確率を計算します\n",
        "    probs = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "\n",
        "    # 上位3つの予測結果を取得します\n",
        "    _, indices = torch.topk(probs, 3)\n",
        "    percentages = probs[indices]\n",
        "\n",
        "    # 推測結果を表示します\n",
        "    for idx, percentage in zip(indices, percentages):\n",
        "        print(\"クラス:\", class_idx[idx.item()], \", 確信度:\", percentage.item())\n",
        "\n",
        "    print('\\n' + '=' * 50 + '\\n')"
      ]
    },
    {
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# ファインチューニングしたいデータセットをロード\n",
        "train_dataset = ...\n",
        "val_dataset = ...\n",
        "\n",
        "# ResNetモデルをロード\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# 最終層をファインチューニング用に置き換える\n",
        "num_classes = len(train_dataset.classes)\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# モデルをファインチューニングモードに設定\n",
        "model.train()\n",
        "\n",
        "# ファインチューニング用のデータローダーを作成\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "# ファインチューニング用の最適化アルゴリズムと損失関数を設定\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# ファインチューニングの実行\n",
        "for epoch in range(10):\n",
        "    for x, y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x)\n",
        "        loss = criterion(y_pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # バリデーションデータでモデルを評価\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for x, y in val_loader:\n",
        "            y_pred = model(x)\n",
        "            _, predicted = torch.max(y_pred.data, 1)\n",
        "            total += y.size(0)\n",
        "            correct += (predicted == y).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f'Epoch: {epoch+1}, Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "# ファインチューニングされたモデルを保存\n",
        "torch.save(model.state_dict(), 'fine_tuned_resnet18.pt')"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "svB7GrNaOUKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ファインチューニング用のデータセットとして動作を確認できる適当なサンプルはありますか？\n",
        "\n",
        "Colab AI\n",
        "ファインチューニング用のデータセットとして動作を確認できる適当なサンプルは、以下の通りです。\n",
        "\n",
        "CIFAR-10\n",
        "CIFAR-10は、10クラスの画像で構成されるデータセットです。\n",
        "CIFAR-10は、画像認識の分野で広く使用されているデータセットです。\n",
        "CIFAR-10は、PyTorchで簡単にロードすることができます。"
      ],
      "metadata": {
        "id": "eay2aTWfVT_V"
      }
    },
    {
      "source": [
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
        "val_dataset = CIFAR10(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "D-ElYQHGVFhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST\n",
        "MNISTは、手書き数字の画像で構成されるデータセットです。\n",
        "MNISTは、画像認識の分野で広く使用されているデータセットです。\n",
        "MNISTは、PyTorchで簡単にロードすることができます。"
      ],
      "metadata": {
        "id": "SMJzk2hlVbVE"
      }
    },
    {
      "source": [
        "from torchvision.datasets import MNIST\n",
        "\n",
        "train_dataset = MNIST(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
        "val_dataset = MNIST(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "okRoaiCsVIQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "これらのデータセットは、どちらもファインチューニング用のデータセットとして動作を確認することができます。\n",
        "\n",
        "この回答を評価\n",
        "\n",
        "Natsuki Oka\n",
        "resnet18をmnistでファインチューニングする、ということですか？\n",
        "\n",
        "Colab AI\n",
        "はい、resnet18をmnistでファインチューニングすることは可能です。\n",
        "\n",
        "しかし、resnet18はもともと大規模な画像認識データセットであるImageNetで学習されたモデルであり、mnistは小さな手書き数字のデータセットであるため、そのままファインチューニングしても十分な性能を発揮できない可能性があります。\n",
        "\n",
        "そのため、ファインチューニングを行う際には、以下の点に注意する必要があります。\n",
        "\n",
        "学習率の設定\n",
        "\n",
        "学習率を小さく設定することで、モデルの重みが大きく更新されるのを防ぎ、過学習を抑制することができます。\n",
        "ファインチューニングする層の選択\n",
        "\n",
        "resnet18のすべての層をファインチューニングするのではなく、最後の数層のみをファインチューニングすることで、過学習を抑制することができます。\n",
        "データ拡張の使用\n",
        "\n",
        "データ拡張を使用することで、データセットのサイズを人工的に増やし、過学習を抑制することができます。\n",
        "以下に、resnet18をmnistでファインチューニングするコード例を示します。"
      ],
      "metadata": {
        "id": "OnTuCoj5VjY7"
      }
    },
    {
      "source": [
        "import torch\n",
        "from torchvision import models\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "# ファインチューニングしたいデータセットをロード\n",
        "train_dataset = MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "val_dataset = MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# ResNet18モデルをロード\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# 最終層をファインチューニング用に置き換える\n",
        "num_classes = len(train_dataset.classes)\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "# モデルをファインチューニングモードに設定\n",
        "model.train()\n",
        "\n",
        "# ファインチューニング用のデータローダーを作成\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "# ファインチューニング用の最適化アルゴリズムと損失関数を設定\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# ファインチューニングの実行\n",
        "for epoch in range("
      ],
      "cell_type": "code",
      "metadata": {
        "id": "o6XpG_WFVKBk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}